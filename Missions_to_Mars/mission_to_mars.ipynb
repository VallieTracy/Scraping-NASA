{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from splinter import Browser\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {\"executable_path\":r\"C:/bin/chromedriver\"}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News\n",
    "\n",
    "* Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "news_title = \"NASA's Next Mars Mission to Investigate Interior of Red Planet\"\n",
    "\n",
    "news_p = \"Preparation of NASA's next spacecraft to Mars, InSight, has ramped up this summer, on course for launch next May from Vandenberg Air Force Base in central California -- the first interplanetary launch in history from America's West Coast.\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the mars Nasa news site\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(url)\n",
    "\n",
    "#Optional delay for loading the page\n",
    "browser.is_element_present_by_css(\"ul.item_list li.slide\", wait_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the browser html to a soup object and then quit the browser\n",
    "browser_html = browser.html\n",
    "news_soup = bs(browser_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_element = news_soup.select_one(\"ul.item_list li.slide\")\n",
    "slide_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title = slide_element.find(\"div\", class_=\"content_title\").find(\"a\").text\n",
    "print(news_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_p = slide_element.find(\"div\", class_=\"article_teaser_body\").text\n",
    "news_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALLIE\n",
    "# url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "# response = requests.get(url)\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "# soup = bs(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parent=soup.select_one(\"ul.item_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#soup.find('div',class_='content_title').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup.find('div',class_='article_teaser_body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALLIE\n",
    "# news_title = soup.find(\"div\", class_=\"content_title\").find(\"a\").text\n",
    "# print(news_title)\n",
    "# not right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALLIE\n",
    "# news_p = soup.find(\"div\", class_=\"rollover_description_inner\n",
    "#                    \").text.strip()\n",
    "# print(news_p)\n",
    "#rollover_description_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "\n",
    "* Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "\n",
    "* Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "* Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "* Make sure to save a complete url string for this image.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16225_hires.jpg'\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all pages\n",
    "for x in range(50):\n",
    "    # HTML object\n",
    "    html = browser.html\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = bs(html, 'html.parser')\n",
    "    # Retrieve image that contains feature image information\n",
    "    feature_image = soup.find('article', class_='product_pod')\n",
    "\n",
    "    # Iterate through each image\n",
    "    for article in articles:\n",
    "        # Use Beautiful Soup's find() method to navigate and retrieve attributes\n",
    "        h3 = article.find('h3')\n",
    "        link = h3.find('a')\n",
    "        href = link['href']\n",
    "        title = link['title']\n",
    "        print('-----------')\n",
    "        print(title)\n",
    "        print('http://books.toscrape.com/' + href)\n",
    "\n",
    "    # Click the 'Next' button on each page\n",
    "    try:\n",
    "        browser.click_link_by_partial_text('MORE')\n",
    "          \n",
    "    except:\n",
    "        print(\"Scraping Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather\n",
    "\n",
    "* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "mars_weather = 'Sol 1801 (Aug 30, 2017), Sunny, high -21C/-5F, low -80C/-112F, pressure at 8.82 hPa, daylight 06:09-17:55'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_twitter_url = 'https://twitter.com/marswxreport?lang=en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(mars_twitter_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_html = browser.html\n",
    "twitter_soup = bs(twitter_html, \"html.parser\")\n",
    "#twitter_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = twitter_soup.find(\"div\", class_=\"css-1dbjc4n\")\n",
    "#parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather = parent.find(\"div\", class_=\"css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0\").text\n",
    "\n",
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "\n",
    "* Visit the Mars Facts webpage [here](https://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "* Use Pandas to convert the data to a HTML table string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_facts_url = 'https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(mars_facts_url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_one_df = tables[0]\n",
    "table_one_df.columns = [\"Mars Planet Profile\", \"Numbers\"]\n",
    "table_one_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_two_df = tables[1]\n",
    "table_two_df\n",
    "#might want to merge these two tables! Don't yet if all that data is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = table_two_df.to_html()\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will want to save a file i think.  but wait until after i merge the tables if i'm going to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres\n",
    "\n",
    "* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "]\n",
    "```\n",
    "\n",
    "- - -\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars hemispheres url\n",
    "hemi_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(hemi_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the browser html to a soup object\n",
    "hemi_html = browser.html\n",
    "hemi_soup = bs(hemi_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"item\"><a class=\"itemLink product-item\" href=\"/search/map/Mars/Viking/cerberus_enhanced\"><img alt=\"Cerberus Hemisphere Enhanced thumbnail\" class=\"thumb\" src=\"/cache/images/dfaf3849e74bf973b59eb50dab52b583_cerberus_enhanced.tif_thumb.png\"/></a><div class=\"description\"><a class=\"itemLink product-item\" href=\"/search/map/Mars/Viking/cerberus_enhanced\"><h3>Cerberus Hemisphere Enhanced</h3></a><span class=\"subtitle\" style=\"float:left\">image/tiff 21 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/><p>Mosaic of the Cerberus hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. This mosaic is composed of 104 Viking Orbiter images acquired…</p></div> <!-- end description --></div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parent html that holds the title and link to individual hemispheres\n",
    "# As it's set up now, this is the parent to the very first hemisphere on the page \n",
    "# each hemisphere is listed under it's own 'item'\n",
    "hemi_parent = hemi_soup.select_one(\"div.result-list div.item\")\n",
    "hemi_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Cerberus Hemisphere Enhanced\n",
      "<div class=\"description\"><a class=\"itemLink product-item\" href=\"/search/map/Mars/Viking/cerberus_enhanced\"><h3>Cerberus Hemisphere Enhanced</h3></a><span class=\"subtitle\" style=\"float:left\">image/tiff 21 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/><p>Mosaic of the Cerberus hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. This mosaic is composed of 104 Viking Orbiter images acquired…</p></div>\n",
      "---------\n",
      "Schiaparelli Hemisphere Enhanced\n",
      "<div class=\"description\"><a class=\"itemLink product-item\" href=\"/search/map/Mars/Viking/schiaparelli_enhanced\"><h3>Schiaparelli Hemisphere Enhanced</h3></a><span class=\"subtitle\" style=\"float:left\">image/tiff 35 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/><p>Mosaic of the Schiaparelli hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. The images were acquired in 1980 during early northern…</p></div>\n",
      "---------\n",
      "Syrtis Major Hemisphere Enhanced\n",
      "<div class=\"description\"><a class=\"itemLink product-item\" href=\"/search/map/Mars/Viking/syrtis_major_enhanced\"><h3>Syrtis Major Hemisphere Enhanced</h3></a><span class=\"subtitle\" style=\"float:left\">image/tiff 25 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/><p>Mosaic of the Syrtis Major hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. This mosaic is composed of about 100 red and violet…</p></div>\n",
      "---------\n",
      "Valles Marineris Hemisphere Enhanced\n",
      "<div class=\"description\"><a class=\"itemLink product-item\" href=\"/search/map/Mars/Viking/valles_marineris_enhanced\"><h3>Valles Marineris Hemisphere Enhanced</h3></a><span class=\"subtitle\" style=\"float:left\">image/tiff 27 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/><p>Mosaic of the Valles Marineris hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. The distance is 2500 kilometers from the surface of…</p></div>\n"
     ]
    }
   ],
   "source": [
    "# Cells below work for getting the first image.  Now trying to figure out how to get all hemispheres using a loop\n",
    "results = hemi_soup.select(\"div.result-list div.item\")\n",
    "\n",
    "for result in results:\n",
    "    title = result.find(\"h3\").text\n",
    "    image_parent = result.find(\"div\", class_=\"description\")\n",
    "        \n",
    "    print(\"---------\")\n",
    "    print(title)\n",
    "    print(image_parent)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# image_parent = hemi_parent.find(\"div\", class_=\"description\")\n",
    "# image_parent\n",
    "# image_link_partial = image_parent.find(\"a\")[\"href\"]\n",
    "# image_link_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the parent divs for all articles\n",
    "results = soup.find_all('div', class_='article-item__top')\n",
    "\n",
    "# loop over results to get article data\n",
    "for result in results:\n",
    "    # scrape the article header \n",
    "    header = result.find('h1', class_='article-item__headline').text\n",
    "    \n",
    "    # scrape the article subheader\n",
    "    subheader = result.find('h2', class_='article-item__subheader').text\n",
    "    \n",
    "    # scrape the datetime\n",
    "    datetime = result.find('span', class_='article-item__date')['data-date'] \n",
    "    \n",
    "    # get only the date from the datetime\n",
    "    date = datetime.split('T')[0]\n",
    "    \n",
    "    # print article data\n",
    "    print('-----------------')\n",
    "    print(header)\n",
    "    print(subheader)\n",
    "    print(date)\n",
    "\n",
    "    # Dictionary to be inserted into MongoDB\n",
    "    post = {\n",
    "        'header': header,\n",
    "        'subheader': subheader,\n",
    "        'date': date,\n",
    "    }\n",
    "\n",
    "    # Insert dictionary into MongoDB as a document\n",
    "    collection.insert_one(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title text listed under parent element within <h3> code\n",
    "title = hemi_parent.find(\"h3\").text\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full image located at a different url\n",
    "# First need image parent\n",
    "image_parent = hemi_parent.find(\"div\", class_=\"description\")\n",
    "image_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Tail' portion of url which will direct us to url with full-size image\n",
    "image_link_partial = image_parent.find(\"a\")[\"href\"]\n",
    "image_link_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('https://astrogeology.usgs.gov' + image_link_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the url where the full-size image lives\n",
    "link = 'https://astrogeology.usgs.gov' + image_link_partial\n",
    "browser.visit(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert browser to html\n",
    "image_html = browser.html\n",
    "\n",
    "#Convert to a soup object\n",
    "image_soup = bs(image_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent element of the full-size image\n",
    "full_img_parent = image_soup.select_one(\"div.wide-image-wrapper div.downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the full-size image url within the parent element\n",
    "img_url = full_img_parent.find(\"a\")[\"href\"]\n",
    "img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
